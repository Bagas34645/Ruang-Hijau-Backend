# Chatbot Architecture & Service Dependencies

## ðŸ—ï¸ Complete System Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                      RUANG HIJAU APPLICATION                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–¼
                        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                        â”‚ FLUTTER APP   â”‚
                        â”‚ (chatbot_page)â”‚
                        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                â–¼
                    HTTP POST /api/chatbot/chat
                                â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚          FLASK BACKEND (app.py)              â”‚
        â”‚  Port: 5000                                  â”‚
        â”‚  Status: ðŸŸ¢ Need to start                    â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                    â–¼                      â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ OLLAMA SERVICE      â”‚  â”‚ RAG DATABASE     â”‚
        â”‚ (Local LLM)         â”‚  â”‚ (TiDB Cloud)     â”‚
        â”‚ Port: 11434         â”‚  â”‚ Host: gateway... â”‚
        â”‚ Status: ðŸŸ¢ Need     â”‚  â”‚ Port: 4000       â”‚
        â”‚         to start    â”‚  â”‚ Status: âœ… Cloud â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                â–¼                         â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ EMBEDDING MODEL     â”‚  â”‚ DOCUMENTS TABLE  â”‚
        â”‚ (BAAI/bge-m3)       â”‚  â”‚ (knowledge base) â”‚
        â”‚ Size: 670MB         â”‚  â”‚                  â”‚
        â”‚ Auto-download: âœ…   â”‚  â”‚                  â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸŽ¯ Services Status Checklist

### âœ… Already Working (Cloud Services)
- **TiDB Cloud Database** - RAG knowledge base
- **Hugging Face Models** - Will auto-download

### ðŸ”§ Need to Start (Local Services)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SERVICE 1: OLLAMA (LLM Service)                   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Command: ollama serve                             â”‚
â”‚  Port: 11434                                       â”‚
â”‚  Status: ðŸ”´ NOT RUNNING (need to start)           â”‚
â”‚  Role: Provides the AI language model              â”‚
â”‚  Time to start: 5-10 seconds                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SERVICE 2: FLASK (Backend API)                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Command: python app.py                            â”‚
â”‚  Port: 5000                                        â”‚
â”‚  Status: ðŸ”´ NOT RUNNING (need to start)           â”‚
â”‚  Role: Handles chatbot requests, orchestrates RAG  â”‚
â”‚  Time to start: 2-3 seconds                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  SERVICE 3: EMBEDDING MODEL (First Time Only)      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Command: ollama pull gemma2:2b                    â”‚
â”‚  Size: ~3.5GB                                      â”‚
â”‚  Status: â³ Need to download (first request auto)  â”‚
â”‚  Role: Local LLM model for processing requests     â”‚
â”‚  Time to download: 5-10 minutes                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸ“Š Request Flow Diagram

```
1. User sends message in Flutter app
   â”‚
   â–¼
2. FLUTTER APP
   â”‚ HTTP POST: {"message": "Apa itu daur ulang?"}
   â–¼
3. FLASK BACKEND receives request
   â”‚ - Parse JSON
   â”‚ - Log request
   â–¼
4. Load LLM & Embedder (first time only, slow)
   â”‚ - sentence-transformers (BAAI/bge-m3)
   â”‚ - ollama client
   â–¼
5. Connect to RAG Database
   â”‚ - TiDB Cloud connection
   â”‚ - Prepare SQL query
   â–¼
6. Embed the user query
   â”‚ - Convert text to vector
   â–¼
7. Search for relevant documents
   â”‚ - Vector similarity search in TiDB
   â”‚ - Find top-5 most relevant documents
   â–¼
8. Build context
   â”‚ - Combine retrieved documents
   â–¼
9. Send prompt to Ollama
   â”‚ - Combine context + question
   â”‚ - Ollama processes and generates response
   â–¼
10. Return response to Flask
    â”‚ - JSON format
    â–¼
11. Flask returns to Flutter app
    â”‚ HTTP 200: {"response": "Daur ulang adalah..."}
    â–¼
12. Flutter displays in chat UI
```

## â±ï¸ Expected Timing

```
First Request (with model loading):
â”œâ”€â”€ Ollama load model: 20-30 seconds
â”œâ”€â”€ Embedding model load: 10-15 seconds
â”œâ”€â”€ Database connection: 2-3 seconds
â”œâ”€â”€ Vector search: 1-2 seconds
â”œâ”€â”€ LLM generation: 5-10 seconds
â””â”€â”€ Total: 40-60 seconds â³ (normal!)

Subsequent Requests (models cached):
â”œâ”€â”€ Database connection: 1-2 seconds
â”œâ”€â”€ Vector search: 1-2 seconds
â”œâ”€â”€ LLM generation: 3-5 seconds
â””â”€â”€ Total: 5-10 seconds âš¡ (fast!)
```

## ðŸš€ Startup Sequence

```
Step 1: Open Terminal 1
  $ ollama serve
  
  Output should show:
  âœ… Listening on 127.0.0.1:11434
  
  (Keep this terminal running)

Step 2: Open Terminal 2
  $ cd Ruang-Hijau-Backend
  $ python app.py
  
  Output should show:
  âœ… Running on http://127.0.0.1:5000
  
  (Keep this terminal running)

Step 3: (Optional) Open Terminal 3
  $ ollama pull gemma2:2b
  
  (Downloads the model, ~5-10 minutes)
  After completion, you're ready to test!

Step 4: Use Flutter App
  - Open chatbot page
  - Send first message
  - Wait 40-60 seconds for first response
  - Subsequent messages should be faster
```

## ðŸ” How to Monitor

```bash
# Terminal 1 (Ollama)
# Watch for:
# - "Listening on 127.0.0.1:11434" âœ…
# - Model loading messages
# - No "error" or "connection refused" âŒ

# Terminal 2 (Flask)
# Watch for:
# - "Running on http://127.0.0.1:5000" âœ…
# - "[1/4] Connecting to database..." âœ…
# - "[2/4] Generating response..." âœ…
# - "âŒ Runtime error" = Issue with Ollama or embedder
# - "âŒ Database error" = Issue with TiDB

# Terminal 3 (Diagnostic)
# Run: python diagnose_chatbot.py
# Should show all components as "healthy" âœ…
```

## ðŸ› Troubleshooting Quick Map

```
Error: 502 Bad Gateway
â”œâ”€ Ollama not running?
â”‚  â””â”€ Run: ollama serve
â”œâ”€ Flask crashed?
â”‚  â””â”€ Check Flask terminal for errors
â””â”€ Dependencies missing?
   â””â”€ Run: pip install -r requirements.txt

Error: Request Timeout (300 seconds)
â”œâ”€ First request?
â”‚  â””â”€ Wait 40-60 seconds, that's normal
â”œâ”€ Model downloading?
â”‚  â””â”€ Run: ollama pull gemma2:2b
â””â”€ System resources low?
   â””â”€ Close other apps, increase timeout

Error: 503 Service Unavailable
â”œâ”€ Ollama unavailable?
â”‚  â””â”€ Run: ollama serve
â”œâ”€ Missing packages?
â”‚  â””â”€ Run: pip install sentence-transformers torch
â””â”€ Database unavailable?
   â””â”€ Check TiDB Cloud account
```

## ðŸ“‹ Dependency Summary

```
Python Packages:
â”œâ”€ Flask >= 2.3.0 âœ…
â”œâ”€ Flask-CORS >= 4.0.0 âœ…
â”œâ”€ mysql-connector-python >= 8.0.0 âœ…
â”œâ”€ python-dotenv >= 1.0.0 âœ…
â”œâ”€ sentence-transformers >= 2.2.0 âœ… (Heavy - 2GB+)
â”œâ”€ torch >= 1.9.0 âœ… (Heavy - 2GB+)
â””â”€ ollama >= 0.1.0 âœ…

System Services:
â”œâ”€ Ollama Local Server ðŸ”´ (MUST START)
â”œâ”€ Flask Python App ðŸ”´ (MUST START)
â”œâ”€ TiDB Cloud Database âœ… (Already running)
â””â”€ Internet Connection âœ… (For model downloads)

Database Files:
â”œâ”€ .env (Configuration) âœ…
â”œâ”€ isrgrootx1.pem (SSL cert) âœ…
â””â”€ knowledge_base.csv (Optional docs) âœ…
```

## âœ¨ Success Indicators

```
âœ… Ollama Terminal
   [âœ“] "Listening on 127.0.0.1:11434"

âœ… Flask Terminal  
   [âœ“] "Running on http://127.0.0.1:5000"
   
âœ… First Chat Message
   [âœ“] ~40-60 second wait (first time)
   [âœ“] Response appears in chat
   [âœ“] No error messages

âœ… Second Chat Message
   [âœ“] ~3-5 second wait
   [âœ“] Much faster!
   
âœ… Diagnostic Script
   $ python diagnose_chatbot.py
   [âœ“] "ALL CHECKS PASSED!"
```

---

**Last Updated:** January 2026
**Quick Links:**
- Full Guide: `CHATBOT_502_FIX.md`
- Quick Fix: `CHATBOT_QUICK_FIX.md`
- Diagnostic: `python diagnose_chatbot.py`
- Startup Helper: `bash start_chatbot.sh`
